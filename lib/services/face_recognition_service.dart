import 'dart:io';
import 'dart:math';
// ğŸŸ¢ [ä¿®å¤1] åˆ é™¤å¤šä½™çš„ import 'dart:typed_data';
import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:image/image.dart' as img;
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';

class FaceRecognitionService {
  Interpreter? _interpreter;
  late final FaceDetector _faceDetector;

  static const int inputSize = 112;
  static const int embeddingSize = 192;
  double threshold = 1.0; 

  // ç¼“å­˜åº•ç‰‡çš„ä¸­é—´æ•°æ®ï¼Œç”¨äº Debug å¯¹æ¯”
  List<double>? _cachedRefEmbedding;
  List<double>? _debugRefInputTensor; // è°ƒè¯•ç”¨ï¼šåº•ç‰‡çš„å½’ä¸€åŒ–æ•°æ®
  int? _debugRefCenterPixel;          // è°ƒè¯•ç”¨ï¼šåº•ç‰‡ä¸­å¿ƒç‚¹åŸå§‹åƒç´ å€¼

  static final FaceRecognitionService _instance = FaceRecognitionService._internal();
  factory FaceRecognitionService() => _instance;
  
  FaceRecognitionService._internal() {
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate,
        enableLandmarks: true, 
        enableClassification: false,
      ),
    );
  }

  Future<void> initialize({
    String assetPath = 'assets/models/mobilefacenet.tflite',
    int threads = 4,
  }) async {
    try {
      final options = InterpreterOptions()..threads = threads;
      _interpreter = await Interpreter.fromAsset(assetPath, options: options);
      _interpreter!.allocateTensors();
      
      var inputShape = _interpreter!.getInputTensor(0).shape;
      var outputShape = _interpreter!.getOutputTensor(0).shape;
      
      debugPrint("âœ… Model Loaded.");
      debugPrint("â„¹ï¸ Model Input: $inputShape");
      debugPrint("â„¹ï¸ Model Output: $outputShape");
      
    } catch (e) {
      debugPrint("âŒ Model load error: $e");
    }
    
  }
void clearReference() {
    _cachedRefEmbedding = null;
    _debugRefInputTensor = null;
    _debugRefCenterPixel = null;
  }
  // ==========================================
  //  æ ¸å¿ƒé€»è¾‘
  // ==========================================

  Future<bool> preloadReference(String path) async {
    debugPrint("\nğŸ”µ [STEP 1] Loading Reference...");
    final file = File(path);
    if (!file.existsSync()) return false;

    // 1. åŠ è½½
    img.Image? rawImage = await _loadImage(file, "REF");
    if (rawImage == null) return false;

    // 2. è£å‰ª
    img.Image? faceImage = await _cropSquareFace(rawImage, label: "REF");
    faceImage ??= rawImage; // é™çº§

    // 3. è®¡ç®— (ä¼šé¡ºä¾¿ç¼“å­˜è°ƒè¯•æ•°æ®)
    var result = await _calculateEmbedding(faceImage, label: "REF");
    if (result == null) return false;

    _cachedRefEmbedding = result.embedding;
    _debugRefInputTensor = result.inputTensor;
    _debugRefCenterPixel = result.centerPixel;

    return true;
  }

  Future<VerifyResult> compareFacesDetailed(String refPath, XFile photo) async {
    debugPrint("\nğŸŸ  [STEP 2] Loading Probe...");
    
    // ç¡®ä¿åº•ç‰‡å·²åŠ è½½
    if (_cachedRefEmbedding == null) {
      await preloadReference(refPath);
    }

    final photoFile = File(photo.path);
    
    // 1. åŠ è½½
    img.Image? rawProbe = await _loadImage(photoFile, "PROBE");
    if (rawProbe == null) return VerifyResult(false, 999.0);

    // 2. è£å‰ª
    img.Image? probeImage = await _cropSquareFace(rawProbe, label: "PROBE");
    probeImage ??= rawProbe;

    // 3. è®¡ç®—
    var result = await _calculateEmbedding(probeImage, label: "PROBE");
    if (result == null || _cachedRefEmbedding == null) return VerifyResult(false, 999.0);

    // ===========================================
    // ğŸš¨ ç»ˆæå¯¹æ¯”ï¼šé€ä¸ªç¯èŠ‚æ£€æŸ¥å·®å¼‚
    // ===========================================
    debugPrint("\nğŸ” ========= DEBUG REPORT =========");
    
    // Check 1: ä¸­å¿ƒåƒç´  (æ£€æŸ¥å›¾ç‰‡æ˜¯å¦ä¸€è‡´/æ—‹è½¬)
    debugPrint("1ï¸âƒ£ Center Pixel (Raw RGB Hex):");
    debugPrint("   REF  : ${_debugRefCenterPixel?.toRadixString(16).toUpperCase()}");
    debugPrint("   PROBE: ${result.centerPixel.toRadixString(16).toUpperCase()}");
    
    // Check 2: è¾“å…¥ Tensor å‰5ä½ (æ£€æŸ¥å½’ä¸€åŒ–/BGRè½¬æ¢)
    debugPrint("2ï¸âƒ£ Input Tensor (Normalized):");
    debugPrint("   REF  : ${_debugRefInputTensor?.sublist(0, 5)}");
    debugPrint("   PROBE: ${result.inputTensor.sublist(0, 5)}");

    // Check 3: è¾“å‡º Embedding å‰5ä½ (æ£€æŸ¥æ¨¡å‹æ¨ç†)
    debugPrint("3ï¸âƒ£ Output Embedding (Normalized):");
    debugPrint("   REF  : ${_cachedRefEmbedding?.sublist(0, 5)}");
    debugPrint("   PROBE: ${result.embedding.sublist(0, 5)}");

    // Check 4: æ¬§æ°è·ç¦»
    double distance = _euclideanDistance(_cachedRefEmbedding!, result.embedding);
    debugPrint("4ï¸âƒ£ Euclidean Distance: $distance");
    debugPrint("ğŸ” ===============================\n");

    return VerifyResult(distance <= threshold, distance);
  }

  // ==========================================
  //  å†…éƒ¨å¤„ç†å‡½æ•°
  // ==========================================

  Future<img.Image?> _loadImage(File file, String label) async {
    try {
      final bytes = await file.readAsBytes();
      img.Image? image = img.decodeImage(bytes);
      if (image == null) return null;
      
      debugPrint("â„¹ï¸ [$label] Raw Size: ${image.width}x${image.height}");
      
      image = img.bakeOrientation(image); // ä¿®å¤æ—‹è½¬
      
      if (image.numChannels != 3) {
        image = image.convert(numChannels: 3);
      }
      return image;
    } catch (e) {
      debugPrint("âŒ [$label] Load error: $e");
      return null;
    }
  }

  Future<img.Image?> _cropSquareFace(img.Image originalImage, {required String label}) async {
    try {
      final tempDir = Directory.systemTemp;
      final tempFile = File('${tempDir.path}/temp_${DateTime.now().microsecondsSinceEpoch}.jpg');
      await tempFile.writeAsBytes(img.encodeJpg(originalImage));
      final inputImage = InputImage.fromFile(tempFile);

      final faces = await _faceDetector.processImage(inputImage);
      tempFile.delete().ignore();

      if (faces.isEmpty) {
        debugPrint("âš ï¸ [$label] No faces detected.");
        return null;
      }

      Face face = faces.reduce((a, b) => (a.boundingBox.width * a.boundingBox.height) > (b.boundingBox.width * b.boundingBox.height) ? a : b);
      final box = face.boundingBox;

      debugPrint("ğŸ“ [$label] Face Box: ${box.left}, ${box.top}, ${box.width}x${box.height}");

      int x = box.left.toInt();
      int y = box.top.toInt();
      int w = box.width.toInt();
      int h = box.height.toInt();
      
      int size = (max(w, h) * 1.2).toInt(); 
      if (size > originalImage.width) size = originalImage.width;
      if (size > originalImage.height) size = originalImage.height;

      int centerX = x + w ~/ 2;
      int centerY = y + h ~/ 2;
      int newX = (centerX - size ~/ 2).clamp(0, originalImage.width - size);
      int newY = (centerY - size ~/ 2).clamp(0, originalImage.height - size);
      
      return img.copyCrop(originalImage, x: newX, y: newY, width: size, height: size);
    } catch (e) {
      debugPrint("âŒ [$label] Crop error: $e");
      return null;
    }
  }

  Future<_InferenceResult?> _calculateEmbedding(img.Image src, {required String label}) async {
    if (_interpreter == null) return null;

    // 1. Resize
    img.Image resized = img.copyResize(src, width: inputSize, height: inputSize);
    
    // ğŸŸ¢ [ä¿®å¤2] Pixel æ— æ³•ç›´æ¥è½¬ intï¼Œéœ€è¦æ‰‹åŠ¨æå– RGB æ‹¼æˆä¸€ä¸ªæ•´æ•°
    var p = resized.getPixel(inputSize ~/ 2, inputSize ~/ 2);
    int centerPixel = (p.r.toInt() << 16) | (p.g.toInt() << 8) | p.b.toInt();

    // 3. å½’ä¸€åŒ– (ä½¿ç”¨ RGB å°è¯•ï¼Œå¦‚æœå¤±è´¥å†åˆ‡å› BGR)
    Float32List inputBytes = Float32List(inputSize * inputSize * 3);
    int pixelIndex = 0;
    
    for (int y = 0; y < inputSize; y++) {
      for (int x = 0; x < inputSize; x++) {
        var pixel = resized.getPixel(x, y);
        
        // æå– RGB
        double r = pixel.r.toDouble();
        double g = pixel.g.toDouble();
        double b = pixel.b.toDouble();

        inputBytes[pixelIndex++] = (r - 127.5) / 128.0;
        inputBytes[pixelIndex++] = (g - 127.5) / 128.0;
        inputBytes[pixelIndex++] = (b - 127.5) / 128.0;
      }
    }

    Object input = inputBytes.reshape([1, inputSize, inputSize, 3]);
    List<List<double>> output = List.generate(1, (_) => List.filled(embeddingSize, 0.0));
    
    try {
      _interpreter!.run(input, output);
    } catch (e) {
      debugPrint("âŒ [$label] Run error: $e");
      return null;
    }

    List<double> finalEmb = _l2Normalize(output[0]);
    
    return _InferenceResult(finalEmb, inputBytes, centerPixel);
  }

  List<double> _l2Normalize(List<double> v) {
    double sum = 0.0;
    // ğŸŸ¢ [ä¿®å¤3] ä¸º for å¾ªç¯æ·»åŠ å¤§æ‹¬å·
    for (var x in v) {
      sum += x * x;
    }
    final norm = sqrt(sum);
    if (norm == 0.0) return v;
    return v.map((e) => e / norm).toList();
  }

  double _euclideanDistance(List<double> a, List<double> b) {
    double sum = 0.0;
    for (int i = 0; i < a.length; i++) {
      double diff = a[i] - b[i];
      sum += diff * diff;
    }
    return sqrt(sum);
  }
}

// è¾…åŠ©ç±»ï¼šå­˜å‚¨ä¸­é—´ç»“æœ
class _InferenceResult {
  final List<double> embedding;
  final List<double> inputTensor; // å½’ä¸€åŒ–åçš„æ•°æ®å‰å‡ ä½
  final int centerPixel;          // ä¸­å¿ƒåƒç´ åŸå§‹å€¼
  _InferenceResult(this.embedding, this.inputTensor, this.centerPixel);
}

class VerifyResult {
  final bool verified;
  final double score;
  VerifyResult(this.verified, this.score);
}