import 'dart:async';
import 'dart:io';
import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:easy_localization/easy_localization.dart';
import 'package:path_provider/path_provider.dart';
import '../services/face_recognition_service.dart';

class FaceCameraView extends StatefulWidget {
  final String? referencePath;

  const FaceCameraView({super.key, this.referencePath});

  @override
  State<FaceCameraView> createState() => _FaceCameraViewState();
}

class _FaceCameraViewState extends State<FaceCameraView> with WidgetsBindingObserver {
  CameraController? _controller;
  bool _isInitialized = false;

  // --- UI çŠ¶æ€ ---
  String _statusText = "";
  Color _statusColor = Colors.white;
  bool _isLoadingReference = true;
  
  // --- æµç¨‹æ§åˆ¶çŠ¶æ€ ---
  // 0: å¯»æ‰¾äººè„¸, 1: è¯·çœ¨çœ¼(æ´»ä½“), 2: æ­£åœ¨éªŒè¯/æ‹ç…§
  int _step = 0; 
  bool _eyesPreviouslyClosed = false; // è®°å½•ä¸Šä¸€å¸§æ˜¯å¦é—­çœ¼
  bool _hasCaptured = false; // é”å®šé˜²æ­¢é‡å¤æäº¤

  // --- é€»è¾‘å¯¹è±¡ ---
  late final FaceDetector _faceDetector;
  bool _isProcessing = false;
  final FaceRecognitionService _faceService = FaceRecognitionService();

  @override
  void initState() {
    super.initState();
    WidgetsBinding.instance.addObserver(this);
    _statusText = 'camera.align'.tr(); 

    // 1. åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨ (å¿…é¡»å¼€å¯ classification ä»¥æ£€æµ‹çœ¨çœ¼)
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: FaceDetectorMode.accurate,
        enableLandmarks: true,
        enableClassification: true, // ğŸŸ¢ å…³é”®ï¼šå¿…é¡»ä¸º true
        enableContours: false,
        minFaceSize: 0.15,
      ),
    );

    // 2. å¹¶è¡Œåˆå§‹åŒ–ï¼šä¸‹è½½å‚è€ƒå›¾ & å¯åŠ¨ç›¸æœº
    _downloadAndInitializeReference();
    _initializeCamera();
  }

  // ä¸‹è½½å‚è€ƒå›¾ç‰‡ï¼ˆå¤„ç†ç½‘ç»œå›¾ç‰‡ï¼‰
  Future<void> _downloadAndInitializeReference() async {
    await _faceService.initialize();
    
    if (widget.referencePath == null) {
      if (mounted) setState(() => _isLoadingReference = false);
      return;
    }

    String path = widget.referencePath!;

    if (path.startsWith('http') || path.startsWith('https')) {
      try {
        if (mounted) setState(() => _statusText = "Loading Profile...");
        
        final request = await HttpClient().getUrl(Uri.parse(path));
        final response = await request.close();
        
        if (response.statusCode == 200) {
          final bytes = await consolidateHttpClientResponseBytes(response);
          final dir = await getTemporaryDirectory();
          final file = File('${dir.path}/temp_ref_face.jpg');
          await file.writeAsBytes(bytes);
          
          await _faceService.preloadReference(file.path);
        }
      } catch (e) {
        debugPrint("Ref download error: $e");
      }
    } else {
      await _faceService.preloadReference(path);
    }

    if (mounted) {
      setState(() {
        _isLoadingReference = false;
        _statusText = 'camera.align'.tr();
      });
    }
  }

  Future<void> _initializeCamera() async {
    final cameras = await availableCameras();
    if (cameras.isEmpty) return;

    final frontCamera = cameras.firstWhere(
      (c) => c.lensDirection == CameraLensDirection.front,
      orElse: () => cameras.first,
    );

    _controller = CameraController(
      frontCamera,
      ResolutionPreset.high, 
      enableAudio: false,
      imageFormatGroup: Platform.isAndroid ? ImageFormatGroup.nv21 : ImageFormatGroup.bgra8888,
    );

    await _controller!.initialize();
    await SystemChrome.setPreferredOrientations([DeviceOrientation.portraitUp]);

    if (!mounted) return;
    
    setState(() => _isInitialized = true);
    _controller!.startImageStream(_processImage);
  }

  // --- å®æ—¶å›¾åƒå¤„ç† ---
  Future<void> _processImage(CameraImage image) async {
    if (_isLoadingReference || _isProcessing || _hasCaptured || !mounted) return;
    _isProcessing = true;

    try {
      final inputImage = _convertCameraImage(image);
      if (inputImage == null) return;

      final faces = await _faceDetector.processImage(inputImage);

      if (faces.isEmpty) {
        if (_step != 0 && mounted) {
          _updateUI(status: 'camera.no_face'.tr(), color: Colors.red, step: 0);
          _eyesPreviouslyClosed = false;
        }
      } else {
        final face = faces.first;
        
        // 1. æ£€æŸ¥æ˜¯å¦å±…ä¸­ (å¯é€‰)
        bool isCentered = _isFaceCentered(face, image.width, image.height);
        if (!isCentered) {
          _updateUI(status: 'camera.center_face'.tr(), color: Colors.orange, step: 0);
          _eyesPreviouslyClosed = false;
        } else {
          // 2. å±…ä¸­åï¼Œè¿›å…¥æ´»ä½“æ£€æµ‹æµç¨‹
          if (_step == 0) {
            // æç¤ºçœ¨çœ¼
            _updateUI(status: "è¯·çœ¨çœ¼\nPlease BLINK", color: Colors.yellowAccent, step: 1);
          } else if (_step == 1) {
            // æ£€æµ‹çœ¨çœ¼åŠ¨ä½œ
            _checkBlinkLiveness(face);
          }
        }
      }
    } catch (e) {
      debugPrint("Process error: $e");
    } finally {
      _isProcessing = false;
    }
  }

  // --- ğŸŸ¢ æ´»ä½“æ£€æµ‹æ ¸å¿ƒé€»è¾‘ ---
  void _checkBlinkLiveness(Face face) {
    final leftOpen = face.leftEyeOpenProbability;
    final rightOpen = face.rightEyeOpenProbability;

    if (leftOpen == null || rightOpen == null) return;

    // é˜ˆå€¼ï¼š< 0.2 é—­çœ¼ï¼Œ> 0.8 ççœ¼
    bool isClosed = (leftOpen < 0.2 && rightOpen < 0.2);
    bool isOpen = (leftOpen > 0.8 && rightOpen > 0.8);

    if (isClosed) {
      _eyesPreviouslyClosed = true; // æ•æ‰åˆ°é—­çœ¼
    } else if (isOpen && _eyesPreviouslyClosed) {
      // æ•æ‰åˆ° é—­çœ¼ -> ççœ¼ï¼Œé€šè¿‡ï¼
      _captureAndVerify();
    }
  }

  // --- æ‹ç…§å¹¶éªŒè¯ ---
  Future<void> _captureAndVerify() async {
    if (_hasCaptured) return;
    
    setState(() {
      _hasCaptured = true;
      _step = 2;
      _statusText = 'camera.verifying'.tr();
      _statusColor = Colors.blue;
    });

    try {
      await _controller!.stopImageStream();
      
      // æ‹ç…§
      final XFile image = await _controller!.takePicture();

      // å¦‚æœæ²¡æœ‰å‚è€ƒå›¾ï¼ˆæ¯”å¦‚æ˜¯å½•å…¥æ¨¡å¼ï¼‰ï¼Œç›´æ¥è¿”å›
      if (widget.referencePath == null) {
        if (mounted) Navigator.pop(context, image);
        return;
      }

      // è¿›è¡Œæ¯”å¯¹
      // æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ‚¨çš„ FaceService æœ‰ compareFacesDetailed æ–¹æ³•
      // å¦‚æœæ²¡æœ‰ï¼Œè¯·æ›¿æ¢ä¸ºæ‚¨ç°æœ‰çš„æ¯”å¯¹é€»è¾‘
      VerifyResult result = await _faceService.compareFacesDetailed(widget.referencePath!, image);

      if (!mounted) return;

      if (result.verified) {
        // éªŒè¯æˆåŠŸ
        Navigator.pop(context, image);
      } else {
        // éªŒè¯å¤±è´¥
        setState(() {
          _statusText = 'camera.failed'.tr();
          _statusColor = Colors.red;
        });
        await _showRetryDialog();
      }

    } catch (e) {
      debugPrint("Capture error: $e");
      _resetCamera();
    }
  }

  Future<void> _showRetryDialog() async {
    await showDialog(
      context: context,
      barrierDismissible: false,
      builder: (context) => AlertDialog(
        title: Text('camera.failed'.tr()),
        content: const Text("Face verification failed. Ensure good lighting."),
        actions: [
          ElevatedButton(
            onPressed: () {
              Navigator.pop(context);
              _resetCamera();
            },
            child: const Text('Retry'),
          )
        ],
      ),
    );
  }

  void _resetCamera() async {
    if (!mounted) return;
    setState(() {
      _hasCaptured = false;
      _step = 0;
      _eyesPreviouslyClosed = false;
      _statusText = 'camera.align'.tr();
      _statusColor = Colors.white;
    });
    
    if (_controller != null) {
      // é‡æ–°å¯åŠ¨æµ
      await _controller!.startImageStream(_processImage);
    }
  }

  void _updateUI({required String status, required Color color, required int step}) {
    // åªæœ‰çŠ¶æ€æ”¹å˜æ—¶æ‰åˆ·æ–° UIï¼Œå‡å°‘ rebuild
    if (_statusText != status || _statusColor != color || _step != step) {
      if (mounted) {
        setState(() {
          _statusText = status;
          _statusColor = color;
          _step = step;
        });
      }
    }
  }

  bool _isFaceCentered(Face face, int imgWidth, int imgHeight) {
    double centerX = face.boundingBox.center.dx;
    double centerY = face.boundingBox.center.dy;
    // å®½æ¾ä¸€ç‚¹çš„ä¸­å¿ƒåˆ¤å®š
    return centerX > imgWidth * 0.2 && centerX < imgWidth * 0.8 &&
           centerY > imgHeight * 0.2 && centerY < imgHeight * 0.8;
  }

  InputImage? _convertCameraImage(CameraImage image) {
    if (_controller == null) return null;
    try {
      final camera = _controller!.description;
      final sensorOrientation = camera.sensorOrientation;
      
      // å¤„ç†æ—‹è½¬ (ç®€ç•¥ç‰ˆï¼Œæ¶µç›–å¤§å¤šæ•°æƒ…å†µ)
      InputImageRotation rotation = InputImageRotation.rotation0deg;
      if (Platform.isAndroid) {
        rotation = InputImageRotationValue.fromRawValue(sensorOrientation) ?? InputImageRotation.rotation270deg;
      } else if (Platform.isIOS) {
        rotation = InputImageRotationValue.fromRawValue(sensorOrientation) ?? InputImageRotation.rotation0deg;
      }

      final format = InputImageFormatValue.fromRawValue(image.format.raw) ?? InputImageFormat.nv21;
      
      final WriteBuffer allBytes = WriteBuffer();
      for (final Plane plane in image.planes) {
        allBytes.putUint8List(plane.bytes);
      }
      final bytes = allBytes.done().buffer.asUint8List();

      return InputImage.fromBytes(
        bytes: bytes,
        metadata: InputImageMetadata(
          size: Size(image.width.toDouble(), image.height.toDouble()),
          rotation: rotation,
          format: format,
          bytesPerRow: image.planes[0].bytesPerRow,
        ),
      );
    } catch (e) {
      return null;
    }
  }

  @override
  void dispose() {
    WidgetsBinding.instance.removeObserver(this);
    _faceDetector.close();
    _controller?.dispose();
    SystemChrome.setPreferredOrientations([
      DeviceOrientation.portraitUp,
      DeviceOrientation.portraitDown,
      DeviceOrientation.landscapeLeft,
      DeviceOrientation.landscapeRight,
    ]);
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    if (!_isInitialized || _controller == null) {
      return const Scaffold(
        backgroundColor: Colors.black,
        body: Center(child: CircularProgressIndicator(color: Colors.white)),
      );
    }

    final size = MediaQuery.of(context).size;
    // ğŸŸ¢ å®šä¹‰é•¿æ–¹å½¢å–æ™¯æ¡†å°ºå¯¸
    final double rectWidth = size.width * 0.8;
    final double rectHeight = size.width * 1.1; // ç¨å¾®é«˜ä¸€ç‚¹çš„é•¿æ–¹å½¢

    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(
        title: Text('camera.title_verify'.tr()),
        backgroundColor: const Color(0xFF15438c),
        foregroundColor: Colors.white,
      ),
      body: Stack(
        fit: StackFit.expand,
        children: [
          CameraPreview(_controller!),
          
          // ğŸŸ¢ é®ç½©å±‚ + é•¿æ–¹å½¢é€æ˜æ¡†
          ColorFiltered(
            colorFilter: ColorFilter.mode(Colors.black.withValues(alpha:0.5), BlendMode.srcOut),
            child: Stack(
              children: [
                Container(
                  decoration: const BoxDecoration(
                    color: Colors.transparent,
                    backgroundBlendMode: BlendMode.dstOut,
                  ),
                ),
                Center(
                  child: Container(
                    width: rectWidth,
                    height: rectHeight,
                    decoration: BoxDecoration(
                      color: Colors.white,
                      // é•¿æ–¹å½¢åœ†è§’
                      borderRadius: BorderRadius.circular(20), 
                    ),
                  ),
                ),
              ],
            ),
          ),

          // ğŸŸ¢ è¾¹æ¡†é«˜äº® (é¢œè‰²éšçŠ¶æ€å˜åŒ–)
          Center(
            child: Container(
              width: rectWidth,
              height: rectHeight,
              decoration: BoxDecoration(
                borderRadius: BorderRadius.circular(20),
                border: Border.all(
                  // 1:é»„è‰²(çœ¨çœ¼æ£€æµ‹ä¸­), 2:ç»¿è‰²(é€šè¿‡), 0:ç™½è‰²(æœªæ£€æµ‹)
                  color: _step == 1 ? Colors.yellowAccent : (_step == 2 ? Colors.greenAccent : Colors.white), 
                  width: 4
                ),
              ),
            ),
          ),

          // æç¤ºæ–‡å­—
          Positioned(
            bottom: size.height * 0.15, 
            left: 20, right: 20,
            child: Column(
              children: [
                if (_step == 1)
                  const Icon(Icons.remove_red_eye, color: Colors.yellowAccent, size: 40),
                const SizedBox(height: 10),
                Text(
                  _statusText,
                  textAlign: TextAlign.center,
                  style: TextStyle(
                    color: _statusColor, 
                    fontSize: 22, 
                    fontWeight: FontWeight.bold,
                    shadows: const [Shadow(color: Colors.black, blurRadius: 4)]
                  ),
                ),
              ],
            ),
          ),

          // Loading Overlay
          if (_hasCaptured || _isLoadingReference)
            Container(
              color: Colors.black54,
              child: Center(
                child: Column(
                  mainAxisSize: MainAxisSize.min,
                  children: [
                    const CircularProgressIndicator(color: Colors.white),
                    const SizedBox(height: 20),
                    Text(_statusText, style: const TextStyle(color: Colors.white, fontSize: 18, fontWeight: FontWeight.bold)),
                  ],
                ),
              ),
            )
        ],
      ),
    );
  }
}